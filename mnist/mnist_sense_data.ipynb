{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "%reload_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from time import time\n",
    "\n",
    "# import tensorflow.contrib.eager as tfe\n",
    "\n",
    "# tf.enable_eager_execution()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "PATH='data/digit-recognizer/'\n",
    "SZ=28\n",
    "BATCH_SIZE=128\n",
    "STEPS = 1000\n",
    "MODEL_DIR='models/mnist_64rs_2dense'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>pixel0</th>\n",
       "      <th>pixel1</th>\n",
       "      <th>pixel2</th>\n",
       "      <th>pixel3</th>\n",
       "      <th>pixel4</th>\n",
       "      <th>pixel5</th>\n",
       "      <th>pixel6</th>\n",
       "      <th>pixel7</th>\n",
       "      <th>pixel8</th>\n",
       "      <th>...</th>\n",
       "      <th>pixel774</th>\n",
       "      <th>pixel775</th>\n",
       "      <th>pixel776</th>\n",
       "      <th>pixel777</th>\n",
       "      <th>pixel778</th>\n",
       "      <th>pixel779</th>\n",
       "      <th>pixel780</th>\n",
       "      <th>pixel781</th>\n",
       "      <th>pixel782</th>\n",
       "      <th>pixel783</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 785 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   label  pixel0  pixel1  pixel2  pixel3  pixel4  pixel5  pixel6  pixel7  \\\n",
       "0      1       0       0       0       0       0       0       0       0   \n",
       "1      0       0       0       0       0       0       0       0       0   \n",
       "2      1       0       0       0       0       0       0       0       0   \n",
       "3      4       0       0       0       0       0       0       0       0   \n",
       "4      0       0       0       0       0       0       0       0       0   \n",
       "\n",
       "   pixel8    ...     pixel774  pixel775  pixel776  pixel777  pixel778  \\\n",
       "0       0    ...            0         0         0         0         0   \n",
       "1       0    ...            0         0         0         0         0   \n",
       "2       0    ...            0         0         0         0         0   \n",
       "3       0    ...            0         0         0         0         0   \n",
       "4       0    ...            0         0         0         0         0   \n",
       "\n",
       "   pixel779  pixel780  pixel781  pixel782  pixel783  \n",
       "0         0         0         0         0         0  \n",
       "1         0         0         0         0         0  \n",
       "2         0         0         0         0         0  \n",
       "3         0         0         0         0         0  \n",
       "4         0         0         0         0         0  \n",
       "\n",
       "[5 rows x 785 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "0    1\n",
       "1    0\n",
       "2    1\n",
       "3    4\n",
       "4    0\n",
       "Name: label, dtype: int64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv(f'{PATH}train.csv')\n",
    "display(data.head())\n",
    "features, labels = data, data.pop('label')\n",
    "labels.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(28, 28)\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import cv2\n",
    "from skimage.transform import resize\n",
    "f = np.asarray(features, dtype=np.float32).reshape(-1, 28,28)\n",
    "# resized_features = []\n",
    "# for i, img in enumerate(f):\n",
    "#     image = resize(img, (224, 224), preserve_range=True)\n",
    "#     resized_features.append(image)\n",
    "#     if i % 1000 == 0:\n",
    "#         print(i)\n",
    "\n",
    "# np.shape(resized_features)\n",
    "image = f[45]\n",
    "plt.imshow(image)\n",
    "# image = cv2.resize(image, dsize=(224, 224), interpolation=cv2.INTER_AREA)\n",
    "# image = np.repeat(image[:, :, np.newaxis], 3, axis=2)\n",
    "plt.imshow(image)\n",
    "print(image.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Numpy input for same type data\n",
    "Pandas input for structure data\n",
    "\"\"\"\n",
    "\n",
    "features = np.asarray(features, dtype=np.float32)\n",
    "labels = np.asarray(labels, dtype=np.int64)\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "train_x, val_x, train_y, val_y = train_test_split(features, labels, test_size=0.2)\n",
    "\n",
    "train_input_fn = tf.estimator.inputs.numpy_input_fn(\n",
    "    x = {'x': train_x},\n",
    "    y = train_y,\n",
    "    batch_size = BATCH_SIZE,\n",
    "    num_epochs=None,\n",
    "    shuffle=True)\n",
    "\n",
    "eval_input_fn = tf.estimator.inputs.numpy_input_fn(\n",
    "    x={\"x\": val_x},\n",
    "    y=val_y,\n",
    "    num_epochs=1,\n",
    "    shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# \"\"\"\n",
    "# Save train and val as csv file\n",
    "# \"\"\"\n",
    "\n",
    "# from sklearn.model_selection import train_test_split\n",
    "# data = pd.read_csv(f'{PATH}train.csv')\n",
    "# train_data, val_data = train_test_split(data, test_size=0.2)\n",
    "# print(np.shape(train_data))\n",
    "\n",
    "# np.savetxt(f\"{PATH}train/train.csv\", train_data, delimiter=\",\")\n",
    "# np.savetxt(f\"{PATH}val/val.csv\", val_data, delimiter=\",\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cnn_model(features, labels, mode, params):\n",
    "    \"\"\"\n",
    "    MODEL\n",
    "    \"\"\"\n",
    "    ## 64 image resized\n",
    "    x = tf.reshape(features[\"x\"], [-1, SZ, SZ, 1]) # Channel first NCWH\n",
    "    x = tf.image.resize_images(x, [64, 64], method=3)\n",
    "    \n",
    "    x = tf.layers.conv2d(x, 32, kernel_size=[5, 5], \n",
    "                             padding=\"same\", activation=tf.nn.relu)\n",
    "    x = tf.layers.max_pooling2d(x, pool_size=[2, 2], strides=2)\n",
    "\n",
    "\n",
    "    x = tf.layers.conv2d(x, 64, kernel_size=[5, 5], \n",
    "                             padding=\"same\", activation=tf.nn.relu)\n",
    "    x = tf.layers.max_pooling2d(x, pool_size=[2, 2], strides=2)\n",
    "\n",
    "\n",
    "    x = tf.layers.conv2d(x, 256, kernel_size=[5, 5], \n",
    "                             padding=\"same\", activation=tf.nn.relu)\n",
    "    x = tf.layers.max_pooling2d(x, pool_size=[2, 2], strides=2)\n",
    "\n",
    "    x_flat = tf.reshape(x, [-1, 8 * 8 * 256])\n",
    "    \n",
    "    ## 2 dense\n",
    "#     input_layer = tf.reshape(features[\"x\"], [-1, SZ, SZ, 1]) # Channel first NCWH\n",
    "#     conv1 = tf.layers.conv2d(input_layer, 32, kernel_size=[5, 5], \n",
    "#                              padding=\"same\", activation=tf.nn.relu)\n",
    "#     pool1 = tf.layers.max_pooling2d(conv1, pool_size=[2, 2], strides=2)\n",
    "#     conv2 = tf.layers.conv2d(pool1, 64, kernel_size=[5, 5], \n",
    "#                              padding=\"same\", activation=tf.nn.relu)\n",
    "#     pool2 = tf.layers.max_pooling2d(conv2, pool_size=[2, 2], strides=2)\n",
    "\n",
    "#     x_flat = tf.reshape(pool2, [-1, 7 * 7 * 64])\n",
    "\n",
    "\n",
    "    dense = tf.layers.dense(inputs=x_flat, units=1024, activation=tf.nn.relu)\n",
    "    dropout = tf.layers.dropout(\n",
    "      inputs=dense, rate=0.4, training=mode == tf.estimator.ModeKeys.TRAIN)\n",
    "\n",
    "    dense = tf.layers.dense(inputs=dropout, units=512, activation=tf.nn.relu)\n",
    "    dropout = tf.layers.dropout(\n",
    "      inputs=dense, rate=0.4, training=mode == tf.estimator.ModeKeys.TRAIN)\n",
    "\n",
    "    logits = tf.layers.dense(inputs=dropout, units=10)\n",
    "    \n",
    "    \"\"\" \n",
    "    PREDICT \n",
    "    \"\"\"\n",
    "    predictions = {\n",
    "      # Generate predictions (for PREDICT and EVAL mode)\n",
    "      \"classes\": tf.argmax(input=logits, axis=1),\n",
    "      # Add `softmax_tensor` to the graph. It is used for PREDICT and by the\n",
    "      # `logging_hook`.\n",
    "      \"probabilities\": tf.nn.softmax(logits, name=\"softmax_tensor\")\n",
    "    }\n",
    "    if mode == tf.estimator.ModeKeys.PREDICT:\n",
    "        return tf.estimator.EstimatorSpec(mode=mode, predictions=predictions)\n",
    "\n",
    "    # Calculate Loss (for both TRAIN and EVAL modes)\n",
    "    loss = tf.losses.sparse_softmax_cross_entropy(labels=labels, logits=logits)\n",
    "\n",
    "\n",
    "    \"\"\" \n",
    "    EVAL \n",
    "    \"\"\"\n",
    "    # Add evaluation metrics (for EVAL mode)\n",
    "    \n",
    "    accuracy = tf.metrics.accuracy(labels=labels,\n",
    "                                    predictions=predictions[\"classes\"],\n",
    "                                    name='acc_op')\n",
    "    metrics={'accuracy': accuracy}\n",
    "    tf.summary.scalar('accuracy', accuracy[1])\n",
    "\n",
    "    if mode == tf.estimator.ModeKeys.EVAL:\n",
    "        return tf.estimator.EstimatorSpec(mode, loss=loss, eval_metric_ops=metrics)\n",
    "\n",
    "    \"\"\" \n",
    "    TRAIN \n",
    "    \"\"\"\n",
    "    # Configure the Training Op (for TRAIN mode)\n",
    "    assert mode == tf.estimator.ModeKeys.TRAIN\n",
    "    optimizer = tf.train.GradientDescentOptimizer(learning_rate=0.001)\n",
    "    train_op = optimizer.minimize(\n",
    "        loss=loss,\n",
    "        global_step=tf.train.get_global_step())\n",
    "    return tf.estimator.EstimatorSpec(mode=mode, loss=loss, train_op=train_op)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Using config: {'_model_dir': 'models/mnist_64rs_2dense', '_tf_random_seed': None, '_save_summary_steps': 100, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 4\n",
      "inter_op_parallelism_threads: 4\n",
      ", '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 100, '_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x7f0d7eea4d30>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}\n"
     ]
    }
   ],
   "source": [
    "# Maximum CPU usage 4 cores\n",
    "session_conf = tf.ConfigProto(\n",
    "      intra_op_parallelism_threads=4,\n",
    "      inter_op_parallelism_threads=4)\n",
    "\n",
    "classifier = tf.estimator.Estimator(\n",
    "    cnn_model, \n",
    "    model_dir=MODEL_DIR,\n",
    "    config=tf.estimator.RunConfig(session_config=session_conf),\n",
    "    params=[]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Calling model_fn.\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Create CheckpointSaverHook.\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:Saving checkpoints for 1 into models/mnist_64rs_2dense/model.ckpt.\n",
      "INFO:tensorflow:loss = 18.504086, step = 0\n",
      "INFO:tensorflow:global_step/sec: 6.33064\n",
      "INFO:tensorflow:loss = 0.55224466, step = 100 (15.796 sec)\n",
      "INFO:tensorflow:global_step/sec: 6.47047\n",
      "INFO:tensorflow:loss = 0.3421954, step = 200 (15.455 sec)\n",
      "INFO:tensorflow:global_step/sec: 6.42134\n",
      "INFO:tensorflow:loss = 0.31255823, step = 300 (15.575 sec)\n",
      "INFO:tensorflow:global_step/sec: 6.50138\n",
      "INFO:tensorflow:loss = 0.27999875, step = 400 (15.380 sec)\n",
      "INFO:tensorflow:global_step/sec: 6.46871\n",
      "INFO:tensorflow:loss = 0.22711183, step = 500 (15.458 sec)\n",
      "INFO:tensorflow:global_step/sec: 6.54322\n",
      "INFO:tensorflow:loss = 0.20637622, step = 600 (15.284 sec)\n",
      "INFO:tensorflow:global_step/sec: 6.39699\n",
      "INFO:tensorflow:loss = 0.1638667, step = 700 (15.634 sec)\n",
      "INFO:tensorflow:global_step/sec: 6.3283\n",
      "INFO:tensorflow:loss = 0.19188131, step = 800 (15.799 sec)\n",
      "INFO:tensorflow:global_step/sec: 6.28202\n",
      "INFO:tensorflow:loss = 0.17264171, step = 900 (15.919 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 1000 into models/mnist_64rs_2dense/model.ckpt.\n",
      "INFO:tensorflow:Loss for final step: 0.13183212.\n",
      "INFO:tensorflow:Calling model_fn.\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Starting evaluation at 2018-05-03-06:56:31\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Restoring parameters from models/mnist_64rs_2dense/model.ckpt-1000\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:Finished evaluation at 2018-05-03-06:56:33\n",
      "INFO:tensorflow:Saving dict for global step 1000: accuracy = 0.97333336, global_step = 1000, loss = 0.083692074\n",
      "INFO:tensorflow:Calling model_fn.\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Create CheckpointSaverHook.\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Restoring parameters from models/mnist_64rs_2dense/model.ckpt-1000\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:Saving checkpoints for 1001 into models/mnist_64rs_2dense/model.ckpt.\n",
      "INFO:tensorflow:loss = 0.15857808, step = 1000\n",
      "INFO:tensorflow:global_step/sec: 6.2439\n",
      "INFO:tensorflow:loss = 0.09014778, step = 1100 (16.015 sec)\n",
      "INFO:tensorflow:global_step/sec: 7.46317\n",
      "INFO:tensorflow:loss = 0.13769542, step = 1200 (13.399 sec)\n",
      "INFO:tensorflow:global_step/sec: 10.83\n",
      "INFO:tensorflow:loss = 0.12531899, step = 1300 (9.234 sec)\n",
      "INFO:tensorflow:global_step/sec: 10.7969\n",
      "INFO:tensorflow:loss = 0.12255192, step = 1400 (9.262 sec)\n",
      "INFO:tensorflow:global_step/sec: 10.4898\n",
      "INFO:tensorflow:loss = 0.1349558, step = 1500 (9.532 sec)\n",
      "INFO:tensorflow:global_step/sec: 10.6216\n",
      "INFO:tensorflow:loss = 0.075253196, step = 1600 (9.415 sec)\n",
      "INFO:tensorflow:global_step/sec: 11.227\n",
      "INFO:tensorflow:loss = 0.13648517, step = 1700 (8.907 sec)\n",
      "INFO:tensorflow:global_step/sec: 10.9293\n",
      "INFO:tensorflow:loss = 0.09145347, step = 1800 (9.150 sec)\n",
      "INFO:tensorflow:global_step/sec: 11.1455\n",
      "INFO:tensorflow:loss = 0.0828955, step = 1900 (8.972 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 2000 into models/mnist_64rs_2dense/model.ckpt.\n",
      "INFO:tensorflow:Loss for final step: 0.07903989.\n",
      "INFO:tensorflow:Calling model_fn.\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Starting evaluation at 2018-05-03-06:58:17\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Restoring parameters from models/mnist_64rs_2dense/model.ckpt-2000\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:Finished evaluation at 2018-05-03-06:58:18\n",
      "INFO:tensorflow:Saving dict for global step 2000: accuracy = 0.9816667, global_step = 2000, loss = 0.058489185\n",
      "INFO:tensorflow:Calling model_fn.\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Create CheckpointSaverHook.\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Restoring parameters from models/mnist_64rs_2dense/model.ckpt-2000\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:Saving checkpoints for 2001 into models/mnist_64rs_2dense/model.ckpt.\n",
      "INFO:tensorflow:loss = 0.07715566, step = 2000\n",
      "INFO:tensorflow:global_step/sec: 10.5452\n",
      "INFO:tensorflow:loss = 0.0491742, step = 2100 (9.484 sec)\n",
      "INFO:tensorflow:global_step/sec: 11.1187\n",
      "INFO:tensorflow:loss = 0.10103544, step = 2200 (8.994 sec)\n",
      "INFO:tensorflow:global_step/sec: 11.1953\n",
      "INFO:tensorflow:loss = 0.045027476, step = 2300 (8.932 sec)\n"
     ]
    }
   ],
   "source": [
    "## Numpy input\n",
    "for _ in range(5):\n",
    "    classifier.train(\n",
    "        input_fn=train_input_fn,\n",
    "        steps=STEPS\n",
    "    )\n",
    "    \n",
    "    # Evaluate the model and print results\n",
    "    eval_results = classifier.evaluate(input_fn=eval_input_fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = pd.read_csv(f'{PATH}test.csv')\n",
    "test_x = np.asarray(test, dtype=np.float32)\n",
    "\n",
    "predict_input_fn = tf.estimator.inputs.numpy_input_fn(\n",
    "    x={\"x\": test_x},\n",
    "    y=None,\n",
    "    num_epochs=1,\n",
    "    shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = classifier.predict(input_fn=predict_input_fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Calling model_fn.\n",
      "trainning 0.05855703353881836\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Restoring parameters from models/mnist_2dense/model.ckpt-63037\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n"
     ]
    }
   ],
   "source": [
    "results=[['ImageId', 'Label']]\n",
    "for i, prediction in enumerate(predictions):\n",
    "    results.append([i+1, prediction['classes']])\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "28001"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.savetxt(\"csv/mnist.csv\", np.asarray(results), delimiter=\",\", fmt=\"%s\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[name: \"/device:CPU:0\"\n",
      "device_type: \"CPU\"\n",
      "memory_limit: 268435456\n",
      "locality {\n",
      "}\n",
      "incarnation: 16755167410071435482\n",
      ", name: \"/device:GPU:0\"\n",
      "device_type: \"GPU\"\n",
      "memory_limit: 9836206490\n",
      "locality {\n",
      "  bus_id: 1\n",
      "  links {\n",
      "  }\n",
      "}\n",
      "incarnation: 13532950072095365337\n",
      "physical_device_desc: \"device: 0, name: GeForce GTX 1080 Ti, pci bus id: 0000:03:00.0, compute capability: 6.1\"\n",
      "]\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.python.client import device_lib\n",
    "print(device_lib.list_local_devices())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
